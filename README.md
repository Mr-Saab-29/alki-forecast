# Alki Demand Forecasting Pipeline

This repository implements a reproducible, end‑to‑end workflow for Alki's demand forecasting challenge. It covers data exploration, model tuning, candidate training with composite scoring, refitting of the best models, probabilistic forecasting, and automated plotting – all from the command line.

---

## 1. Project Structure

```
.
├── configs/                     # Model configuration YAMLs
│   ├── model_matrix.yaml        # Baseline candidate matrix
│   └── model_matrix_tuned.yaml  # Generated by tuning (if run)
├── data/
│   └── processed/cleaned_data.csv   # Daily demand per customer (input)
├── outputs/                     # Generated artifacts (created by pipeline)
│   ├── cv/candidates/           # CV metrics, best_models_composite.yaml
│   ├── forecasts/               # forecast_quantiles.csv
│   ├── models/                  # Pickled/serialized fitted models
│   ├── plots/                   # Forecast plots per customer
│   ├── reports/                 # EDA summaries
│   └── tuning/                  # Hyper-parameter search logs
├── src/
│   ├── eval/                    # CV / tuning logic
│   ├── pipeline/                # CLI orchestration scripts
│   ├── features/, models/, utils/ …
│   └── pipeline/save_models_and_forecast.py
├── Makefile                     # CLI entrypoints (eda, tune, train, forecast, plots, all)
└── README.md
```

---

## 2. Environment Setup

1. Install uv
   ```bash
   pip install uv
   ```
2. Create Virtual environment and install the dependencies:
   
   ```bash
   uv sync
   ```
4. Ensure `data/raw/train_set.csv` is available

---

## 3. Available Commands

All workflows are accessible via `make`. Each target prints progress and suppresses ML warnings, so the terminal output stays clean.

| Command             | Description                                                                                          |
|---------------------|------------------------------------------------------------------------------------------------------|
| `make preprocess`   | Converts raw CSV (`data/raw/train set.csv`) to cleaned dataset (`data/processed/cleaned_data.csv`). |
| `make eda`          | Generates simple dataset summary (`outputs/reports/eda_summary.csv` & `.json`).                     |
| `make tune`         | Runs per-customer hyper-parameter search (grid/random). Saves tuned matrix to `configs/model_matrix_tuned.yaml` and tuning metrics to `outputs/tuning/`. |
| `make train`        | Runs cross-validation using the tuned matrix if it exists (fallback: `configs/model_matrix.yaml`). Produces composite-scored results, peak diagnostics and `best_models_composite.yaml` under `outputs/cv/candidates/`. |
| `make forecast`     | Refits the selected best models on full history, using deterministic exogenous features for classical models. Saves model files to `outputs/models/` and 21‑day P10/P50/P90 forecasts to `outputs/forecasts/forecast_quantiles.csv`. |
| `make plots`        | Generates PNG charts combining recent history and forecast quantiles for every customer (`outputs/plots/`). |
| `make all`          | Runs `eda → train → forecast → plots` sequentially.                                            |
| `make clean`        | Removes generated artifacts (`outputs/*`).                                                           |

> **Tip:** You can rerun `make train` after manual tweaks to `configs/model_matrix.yaml`; it will ignore the tuned file if it has been deleted.

---

## 4. Workflow Details

1. **Preprocessing** (`src/pipeline/run_preprocess.py`): Loads `data/raw/train set.csv`, normalises column names to `CUSTOMER`, `DATE`, `QUANTITY`, and writes `data/processed/cleaned_data.csv`.
2. **EDA** (`src/pipeline/run_eda.py`): Summarises coverage, min/max dates, and basic statistics per customer.
3. **Tuning** (`src/pipeline/run_tuning.py`): Searches model params per customer (grid or random) and writes the tuned config.
4. **Training** (`src/pipeline/run_training.py`):
   - Builds deterministic feature matrices (calendar, holidays) and full feature matrices (lags, rolling stats).
   - Runs rolling CV via `run_candidates_per_customer`, recording MAE, RMSE, sMAPE.
   - Normalises metrics and computes a weighted composite score (0.3·MAE + 0.5·RMSE + 0.2·sMAPE).
   - Stores detailed predictions, summary tables, peak diagnostics, and `best_models_composite.yaml`.
5. **Forecasting** (`src/pipeline/run_forecast.py`):
   - Refits each best model (GBM, ARIMA/SARIMA/ETS, Prophet) on the full history.
   - Uses deterministic future features for classical models to maintain exogenous context.
   - Outputs 21-day P10/P50/P90 forecasts with a simple residual-based normal band.
6. **Plotting** (`src/pipeline/plot_forecasts.py`): For each customer, renders a chart with the last 90 days of actuals plus the forecast quantile band.

---

## 5. Key Outputs

- `outputs/reports/eda_summary.{csv,json}` – EDA overview.
- `outputs/tuning/` – Hyper-parameter search logs.
- `outputs/cv/candidates/` – Per-fold metrics, summaries, detailed forecasts, peak diagnostics, and `best_models_composite.yaml`.
- `outputs/models/` – Serialized final models (LightGBM/XGBoost pickles, Statsmodels ARIMA/SARIMA/ETS pickles, Prophet JSON).
- `outputs/forecasts/forecast_quantiles.csv` – 21-day P10/P50/P90 forecasts per customer.
- `outputs/plots/*.png` – Visualizations combining history and forecast bands.

---

## 6. Extending / Customising

- **Config tweaking:** Modify `configs/model_matrix.yaml` to adjust candidate models, families, or CV settings. Re-run `make train` (and optionally `make forecast`).
- **Composite weights:** Adjust the `composite_weights` argument in `run_candidates_per_customer` (invoked in `run_training.py`) for different MAE/RMSE/sMAPE priorities.
- **Forecast horizon:** Pass `--horizon <days>` to `make forecast` or directly to `run_forecast.py`.
- **Plot history length:** `make plots HISTORY_DAYS=<n>` (e.g., `make plots HISTORY_DAYS=120`).

---

## 7. Troubleshooting

- **Missing Stan backend (Prophet):** Prophet gracefully falls back to an ETS model if the Stan backend isn’t installed, without terminal warnings.
- **LightGBM warnings:** All training/tuning scripts suppress LightGBM “No further splits with positive gain” messages.
- **Dependencies:** Ensure the environment includes Prophet, statsmodels, lightgbm/xgboost, pandas, numpy, matplotlib, etc.

---

## 8. Reproducibility Checklist

1. Install dependencies with `uv` (e.g. `uv pip install -r requirements.txt`).
2. Place the raw CSV at `data/raw/train set.csv` (ensure the file name matches, including space). Columns may be named flexibly (e.g. `client`, `qty`); the preprocessing step normalises them to `CUSTOMER`, `DATE`, `QUANTITY`.
3. Run `make all` (this executes `preprocess → eda → train → forecast → plots`).
4. Inspect results in `outputs/` (reports, tuning logs, CV summaries, best models, models, forecasts, plots).
5. Modify configs / rerun individual stages as needed.

Following these steps allows anyone to reproduce the full forecasting pipeline, from raw data inspection to final plots, using the same commands displayed here.

---

## 9. Licence

This project is provided as part of Alki's technical assessment. Please adapt or extend as needed for your organisation or interview follow-up.
